{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(value):\n",
    "    array = np.array(value)\n",
    "    mean_array = np.mean(array, axis=0)\n",
    "    median_array = np.median(array, axis=0)\n",
    "    max_array = np.max(array, axis=0)\n",
    "    min_array = np.min(array, axis=0)\n",
    "    sd_array = np.std(array, axis=0)\n",
    "    concatenated_array = np.concatenate((mean_array, median_array, max_array, min_array, sd_array))\n",
    "    return concatenated_array\n",
    "\n",
    "def process_line(index, line):\n",
    "    row = json.loads(line)\n",
    "    parsed_row = parse_row(row)\n",
    "    print(f\"Processed line {index + 1}\")\n",
    "    return parsed_row\n",
    "\n",
    "def parse_row(row):\n",
    "    ls = []\n",
    "\n",
    "    for key,value in row.items():\n",
    "        ls.append(key)\n",
    "        for key1, value1 in value.items():\n",
    "            ls.append(key1)\n",
    "            for key2, value2 in value1.items():\n",
    "                ls.append(key2)\n",
    "                whole_set = generate_features(value2).tolist()\n",
    "                ls += whole_set\n",
    "\n",
    "    return ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse Json\n",
    "def parse_row(row):\n",
    "    ls = []\n",
    "    for key,value in row.items():\n",
    "        ls.append(key)\n",
    "        for key1, value1 in value.items():\n",
    "            ls.append(key1)\n",
    "            for key2, value2 in value1.items():\n",
    "                ls.append(key2)\n",
    "                whole_set = generate_features(value2).tolist()\n",
    "                ls += whole_set\n",
    "\n",
    "    return ls\n",
    "\n",
    "def process_line(index, line):\n",
    "    row = json.loads(line)\n",
    "    parsed_row = parse_row(row)\n",
    "    print(f\"Processed line {index + 1}\")\n",
    "    return parsed_row\n",
    "\n",
    "def parse_json(json_path,csv_path):\n",
    "    with gzip.open(json_path, 'rt') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    print(lines)\n",
    "\n",
    "    # Create new dimensions\n",
    "    columns = [\"transcript_id\", \"transcript_position\", \"seq\"]\n",
    "    values = [\"dt_1\", \"sd_1\", \"curr_1\", \"dt_2\", \"sd_2\", \"curr_2\", \"dt_3\", \"sd_3\", \"curr_3\"]\n",
    "\n",
    "    for aggregate in [\"mean\",\"median\",\"max\",\"min\",\"sd\"]:\n",
    "        for val in values:\n",
    "            columns.append(f\"{aggregate}_{val}\")\n",
    "\n",
    "    parsed_rows = []  \n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        future_to_index = {executor.submit(process_line, i, line): i for i, line in enumerate(lines)}\n",
    "        for future in as_completed(future_to_index):\n",
    "            parsed_row = future.result()\n",
    "            parsed_rows.append(parsed_row)\n",
    "\n",
    "    df = pd.DataFrame(parsed_rows, columns = columns)\n",
    "    \n",
    "    df[\"transcript_position\"] = df[\"transcript_position\"].astype(int)\n",
    "    df = df.sort_values(by = [\"transcript_id\",\"transcript_position\"])\n",
    "\n",
    "    labels = pd.read_csv(csv_path)\n",
    "    df_with_labels = df.merge(labels, on = [\"transcript_id\",\"transcript_position\"])\n",
    "\n",
    "    return df_with_labels\n",
    "\n",
    "df = parse_json('data/dataset0.json.gz','data/data.info.labelled')\n",
    "df.to_parquet(\"data/data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('data/dataset0.json.gz', 'rt') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed line 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(process_line(0, lines[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet(\"train.parquet\")\n",
    "test_df = pd.read_parquet(\"test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[23273     0]\n",
      " [ 1095     0]]\n",
      "Accuracy: 0.96\n",
      "ROC AUC: 0.71\n",
      "PR AUC: 0.09\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc, accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "y_train = train_df['label'] \n",
    "X_train = train_df.drop(columns=['label','transcript_id', 'transcript_position', 'seq','gene_id'])\n",
    "\n",
    "y_test = test_df['label'] \n",
    "X_test = test_df.drop(columns=['label','transcript_id', 'transcript_position', 'seq','gene_id']) \n",
    "\n",
    "log_reg = LogisticRegression(random_state=42, max_iter=100000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred = log_reg.predict(X_test)\n",
    "y_proba = log_reg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "print(f'ROC AUC: {roc_auc:.2f}')\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_proba)\n",
    "pr_auc = auc(recall, precision)\n",
    "print(f'PR AUC: {pr_auc:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[23135   138]\n",
      " [  851   244]]\n",
      "Accuracy: 0.96\n",
      "ROC AUC: 0.88\n",
      "PR AUC: 0.41\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc, accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "y_train = train_df['label'] \n",
    "X_train = train_df.drop(columns=['label','transcript_id', 'transcript_position', 'seq','gene_id'])\n",
    "\n",
    "y_test = test_df['label'] \n",
    "X_test = test_df.drop(columns=['label','transcript_id', 'transcript_position', 'seq','gene_id']) \n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred = rf_model.predict(X_test)\n",
    "y_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "print(f'ROC AUC: {roc_auc:.2f}')\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_proba)\n",
    "pr_auc = auc(recall, precision)\n",
    "print(f'PR AUC: {pr_auc:.2f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SPUR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
