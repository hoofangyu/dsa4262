{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(array):\n",
    "    mean_array = np.mean(array, axis=0)\n",
    "    median_array = np.median(array, axis=0)\n",
    "    max_array = np.max(array, axis=0)\n",
    "    min_array = np.min(array, axis=0)\n",
    "    sd_array = np.std(array, axis=0)\n",
    "    concatenated_array = np.concatenate((mean_array, median_array, max_array, min_array, sd_array))\n",
    "    return concatenated_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_samples(array):\n",
    "    kmeans = KMeans(n_clusters=2, random_state=0)\n",
    "    kmeans.fit(array)\n",
    "    labels = kmeans.labels_\n",
    "    cluster_1 = array[labels == 0]\n",
    "    cluster_2 = array[labels == 1]\n",
    "    return cluster_1, cluster_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed line 1\n"
     ]
    }
   ],
   "source": [
    "# Parse Json\n",
    "def parse_row(row):\n",
    "    ls = []\n",
    "    for key,value in row.items():\n",
    "        ls.append(key)\n",
    "        for key1, value1 in value.items():\n",
    "            ls.append(key1)\n",
    "            for key2, value2 in value1.items():\n",
    "                ls.append(key2)\n",
    "                array = np.array(value2)\n",
    "                cluster_1, cluster_2 = cluster_samples(array)\n",
    "                \n",
    "                whole_set = generate_features(array).tolist()\n",
    "                cluster_1_set = generate_features(cluster_1).tolist()\n",
    "                cluster_2_set = generate_features(cluster_2).tolist()\n",
    "                ls += whole_set + cluster_1_set + cluster_2_set\n",
    "    return ls\n",
    "\n",
    "def process_line(index, line):\n",
    "    row = json.loads(line)\n",
    "    parsed_row = parse_row(row)\n",
    "    print(f\"Processed line {index + 1}\")\n",
    "    return parsed_row\n",
    "\n",
    "def parse_json(json_path,csv_path):\n",
    "    with gzip.open(json_path, 'rt') as f:\n",
    "        lines = f.readlines()[:1]\n",
    "\n",
    "    # Create new dimensions\n",
    "    columns = [\"transcript_id\", \"transcript_position\", \"seq\"]\n",
    "    values = [\"dt_1\", \"sd_1\", \"curr_1\", \"dt_2\", \"sd_2\", \"curr_2\", \"dt_3\", \"sd_3\", \"curr_3\"]\n",
    "\n",
    "    for data_range in [\"whole\", \"cluster_1\", \"cluster_2\"]:\n",
    "        for aggregate in [\"mean\",\"median\",\"max\",\"min\",\"sd\"]:\n",
    "            for val in values:\n",
    "                columns.append(f\"{data_range}_{aggregate}_{val}\")\n",
    "\n",
    "    parsed_rows = []  \n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        future_to_index = {executor.submit(process_line, i, line): i for i, line in enumerate(lines)}\n",
    "        for future in as_completed(future_to_index):\n",
    "            parsed_row = future.result()\n",
    "            parsed_rows.append(parsed_row)\n",
    "\n",
    "    df = pd.DataFrame(parsed_rows, columns = columns)\n",
    "    \n",
    "    df[\"transcript_position\"] = df[\"transcript_position\"].astype(int)\n",
    "    df = df.sort_values(by = [\"transcript_id\",\"transcript_position\"])\n",
    "\n",
    "    labels = pd.read_csv(csv_path)\n",
    "    df_with_labels = df.merge(labels, on = [\"transcript_id\",\"transcript_position\"])\n",
    "\n",
    "    return df_with_labels\n",
    "\n",
    "df = parse_json('data/dataset0.json.gz','data/data.info.labelled')\n",
    "df.to_parquet(\"data/data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet(\"train.parquet\")\n",
    "test_df = pd.read_parquet(\"test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[23273     0]\n",
      " [ 1095     0]]\n",
      "Accuracy: 0.96\n",
      "ROC AUC: 0.71\n",
      "PR AUC: 0.09\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc, accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "y_train = train_df['label'] \n",
    "X_train = train_df.drop(columns=['label','transcript_id', 'transcript_position', 'seq','gene_id'])\n",
    "\n",
    "y_test = test_df['label'] \n",
    "X_test = test_df.drop(columns=['label','transcript_id', 'transcript_position', 'seq','gene_id']) \n",
    "\n",
    "log_reg = LogisticRegression(random_state=42, max_iter=100000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred = log_reg.predict(X_test)\n",
    "y_proba = log_reg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "print(f'ROC AUC: {roc_auc:.2f}')\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_proba)\n",
    "pr_auc = auc(recall, precision)\n",
    "print(f'PR AUC: {pr_auc:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[23135   138]\n",
      " [  851   244]]\n",
      "Accuracy: 0.96\n",
      "ROC AUC: 0.88\n",
      "PR AUC: 0.41\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc, accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "y_train = train_df['label'] \n",
    "X_train = train_df.drop(columns=['label','transcript_id', 'transcript_position', 'seq','gene_id'])\n",
    "\n",
    "y_test = test_df['label'] \n",
    "X_test = test_df.drop(columns=['label','transcript_id', 'transcript_position', 'seq','gene_id']) \n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred = rf_model.predict(X_test)\n",
    "y_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "print(f'ROC AUC: {roc_auc:.2f}')\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_proba)\n",
    "pr_auc = auc(recall, precision)\n",
    "print(f'PR AUC: {pr_auc:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"data/dataset_all_features.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 96821\n",
      "Test set size: 25017\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming your dataset is in a DataFrame named df and 'column_name' is the column you want to split on\n",
    "\n",
    "# Step 1: Get the unique values from the specified column\n",
    "unique_values = df['gene_id'].unique()\n",
    "\n",
    "# Step 2: Perform an 80-20 split on the unique values\n",
    "train_values, test_values = train_test_split(unique_values, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Filter the dataset based on the train and test values\n",
    "train_df = df[df['gene_id'].isin(train_values)]\n",
    "test_df = df[df['gene_id'].isin(test_values)]\n",
    "\n",
    "# Now train_df and test_df are your train and test datasets with no overlap on 'column_name'\n",
    "print(f\"Train set size: {len(train_df)}\")\n",
    "print(f\"Test set size: {len(test_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_parquet(\"data/train_all_features.parquet\")\n",
    "test_df.to_parquet(\"data/test_all_features.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>transcript_position</th>\n",
       "      <th>seq</th>\n",
       "      <th>whole_mean_dt_1</th>\n",
       "      <th>whole_mean_sd_1</th>\n",
       "      <th>whole_mean_curr_1</th>\n",
       "      <th>whole_mean_dt_2</th>\n",
       "      <th>whole_mean_sd_2</th>\n",
       "      <th>whole_mean_curr_2</th>\n",
       "      <th>whole_mean_dt_3</th>\n",
       "      <th>...</th>\n",
       "      <th>cluster_2_sd_sd_1</th>\n",
       "      <th>cluster_2_sd_curr_1</th>\n",
       "      <th>cluster_2_sd_dt_2</th>\n",
       "      <th>cluster_2_sd_sd_2</th>\n",
       "      <th>cluster_2_sd_curr_2</th>\n",
       "      <th>cluster_2_sd_dt_3</th>\n",
       "      <th>cluster_2_sd_sd_3</th>\n",
       "      <th>cluster_2_sd_curr_3</th>\n",
       "      <th>gene_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ENST00000000412</td>\n",
       "      <td>355</td>\n",
       "      <td>GAAACTA</td>\n",
       "      <td>0.007340</td>\n",
       "      <td>2.977180</td>\n",
       "      <td>108.360000</td>\n",
       "      <td>0.007782</td>\n",
       "      <td>2.608600</td>\n",
       "      <td>106.584000</td>\n",
       "      <td>0.007045</td>\n",
       "      <td>...</td>\n",
       "      <td>2.295391</td>\n",
       "      <td>2.368845</td>\n",
       "      <td>0.003721</td>\n",
       "      <td>0.605664</td>\n",
       "      <td>1.576356</td>\n",
       "      <td>0.003138</td>\n",
       "      <td>0.442328</td>\n",
       "      <td>2.147127</td>\n",
       "      <td>ENSG00000003056</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ENST00000000412</td>\n",
       "      <td>367</td>\n",
       "      <td>GGGACCG</td>\n",
       "      <td>0.008988</td>\n",
       "      <td>3.961489</td>\n",
       "      <td>118.638298</td>\n",
       "      <td>0.007403</td>\n",
       "      <td>6.045319</td>\n",
       "      <td>122.489362</td>\n",
       "      <td>0.006636</td>\n",
       "      <td>...</td>\n",
       "      <td>1.113159</td>\n",
       "      <td>2.396142</td>\n",
       "      <td>0.002825</td>\n",
       "      <td>1.860764</td>\n",
       "      <td>2.381905</td>\n",
       "      <td>0.004161</td>\n",
       "      <td>1.457417</td>\n",
       "      <td>2.129269</td>\n",
       "      <td>ENSG00000003056</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ENST00000000412</td>\n",
       "      <td>496</td>\n",
       "      <td>AGGACTG</td>\n",
       "      <td>0.011065</td>\n",
       "      <td>7.299608</td>\n",
       "      <td>115.549020</td>\n",
       "      <td>0.009377</td>\n",
       "      <td>5.986667</td>\n",
       "      <td>125.666667</td>\n",
       "      <td>0.006474</td>\n",
       "      <td>...</td>\n",
       "      <td>1.764011</td>\n",
       "      <td>2.193497</td>\n",
       "      <td>0.004701</td>\n",
       "      <td>1.673851</td>\n",
       "      <td>1.558126</td>\n",
       "      <td>0.003241</td>\n",
       "      <td>0.891852</td>\n",
       "      <td>1.524671</td>\n",
       "      <td>ENSG00000003056</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ENST00000000412</td>\n",
       "      <td>501</td>\n",
       "      <td>TGGACTG</td>\n",
       "      <td>0.006904</td>\n",
       "      <td>2.803571</td>\n",
       "      <td>119.142857</td>\n",
       "      <td>0.010334</td>\n",
       "      <td>5.950893</td>\n",
       "      <td>123.821429</td>\n",
       "      <td>0.010214</td>\n",
       "      <td>...</td>\n",
       "      <td>1.846205</td>\n",
       "      <td>1.564059</td>\n",
       "      <td>0.003473</td>\n",
       "      <td>3.109129</td>\n",
       "      <td>2.829401</td>\n",
       "      <td>0.005521</td>\n",
       "      <td>1.089678</td>\n",
       "      <td>1.202462</td>\n",
       "      <td>ENSG00000003056</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ENST00000000412</td>\n",
       "      <td>547</td>\n",
       "      <td>CAGACAG</td>\n",
       "      <td>0.006961</td>\n",
       "      <td>4.949231</td>\n",
       "      <td>108.373077</td>\n",
       "      <td>0.009155</td>\n",
       "      <td>5.005962</td>\n",
       "      <td>123.750000</td>\n",
       "      <td>0.011251</td>\n",
       "      <td>...</td>\n",
       "      <td>1.011763</td>\n",
       "      <td>3.794733</td>\n",
       "      <td>0.003542</td>\n",
       "      <td>1.812695</td>\n",
       "      <td>2.289105</td>\n",
       "      <td>0.008535</td>\n",
       "      <td>0.998551</td>\n",
       "      <td>1.012373</td>\n",
       "      <td>ENSG00000003056</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121833</th>\n",
       "      <td>ENST00000641834</td>\n",
       "      <td>1348</td>\n",
       "      <td>GGGACAT</td>\n",
       "      <td>0.009594</td>\n",
       "      <td>3.294164</td>\n",
       "      <td>118.232877</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>4.929726</td>\n",
       "      <td>116.342466</td>\n",
       "      <td>0.006555</td>\n",
       "      <td>...</td>\n",
       "      <td>1.174303</td>\n",
       "      <td>2.235561</td>\n",
       "      <td>0.004556</td>\n",
       "      <td>1.678792</td>\n",
       "      <td>2.706338</td>\n",
       "      <td>0.005078</td>\n",
       "      <td>2.342449</td>\n",
       "      <td>3.736387</td>\n",
       "      <td>ENSG00000167747</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121834</th>\n",
       "      <td>ENST00000641834</td>\n",
       "      <td>1429</td>\n",
       "      <td>CTGACAC</td>\n",
       "      <td>0.008393</td>\n",
       "      <td>4.511014</td>\n",
       "      <td>110.969565</td>\n",
       "      <td>0.010305</td>\n",
       "      <td>9.105797</td>\n",
       "      <td>114.927536</td>\n",
       "      <td>0.005568</td>\n",
       "      <td>...</td>\n",
       "      <td>1.979405</td>\n",
       "      <td>3.978471</td>\n",
       "      <td>0.004743</td>\n",
       "      <td>1.382768</td>\n",
       "      <td>2.568104</td>\n",
       "      <td>0.003849</td>\n",
       "      <td>0.796583</td>\n",
       "      <td>3.087344</td>\n",
       "      <td>ENSG00000167747</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121835</th>\n",
       "      <td>ENST00000641834</td>\n",
       "      <td>1531</td>\n",
       "      <td>TGGACAC</td>\n",
       "      <td>0.008161</td>\n",
       "      <td>3.918438</td>\n",
       "      <td>113.968750</td>\n",
       "      <td>0.006877</td>\n",
       "      <td>4.759687</td>\n",
       "      <td>113.562500</td>\n",
       "      <td>0.006410</td>\n",
       "      <td>...</td>\n",
       "      <td>1.174073</td>\n",
       "      <td>2.582586</td>\n",
       "      <td>0.004565</td>\n",
       "      <td>1.179861</td>\n",
       "      <td>1.791664</td>\n",
       "      <td>0.003236</td>\n",
       "      <td>1.046608</td>\n",
       "      <td>1.858941</td>\n",
       "      <td>ENSG00000167747</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121836</th>\n",
       "      <td>ENST00000641834</td>\n",
       "      <td>1537</td>\n",
       "      <td>CTGACCA</td>\n",
       "      <td>0.008044</td>\n",
       "      <td>3.191228</td>\n",
       "      <td>109.354386</td>\n",
       "      <td>0.007419</td>\n",
       "      <td>6.552982</td>\n",
       "      <td>123.263158</td>\n",
       "      <td>0.006472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.796188</td>\n",
       "      <td>4.831773</td>\n",
       "      <td>0.002296</td>\n",
       "      <td>2.261881</td>\n",
       "      <td>2.397088</td>\n",
       "      <td>0.001914</td>\n",
       "      <td>0.543752</td>\n",
       "      <td>1.941561</td>\n",
       "      <td>ENSG00000167747</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121837</th>\n",
       "      <td>ENST00000641834</td>\n",
       "      <td>1693</td>\n",
       "      <td>TTGACAT</td>\n",
       "      <td>0.008788</td>\n",
       "      <td>4.090577</td>\n",
       "      <td>105.807692</td>\n",
       "      <td>0.006907</td>\n",
       "      <td>8.702885</td>\n",
       "      <td>113.134615</td>\n",
       "      <td>0.008337</td>\n",
       "      <td>...</td>\n",
       "      <td>1.977663</td>\n",
       "      <td>4.798291</td>\n",
       "      <td>0.003249</td>\n",
       "      <td>2.177636</td>\n",
       "      <td>3.596874</td>\n",
       "      <td>0.004098</td>\n",
       "      <td>1.326168</td>\n",
       "      <td>3.045585</td>\n",
       "      <td>ENSG00000167747</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96821 rows Ã— 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          transcript_id  transcript_position      seq  whole_mean_dt_1  \\\n",
       "18      ENST00000000412                  355  GAAACTA         0.007340   \n",
       "19      ENST00000000412                  367  GGGACCG         0.008988   \n",
       "20      ENST00000000412                  496  AGGACTG         0.011065   \n",
       "21      ENST00000000412                  501  TGGACTG         0.006904   \n",
       "22      ENST00000000412                  547  CAGACAG         0.006961   \n",
       "...                 ...                  ...      ...              ...   \n",
       "121833  ENST00000641834                 1348  GGGACAT         0.009594   \n",
       "121834  ENST00000641834                 1429  CTGACAC         0.008393   \n",
       "121835  ENST00000641834                 1531  TGGACAC         0.008161   \n",
       "121836  ENST00000641834                 1537  CTGACCA         0.008044   \n",
       "121837  ENST00000641834                 1693  TTGACAT         0.008788   \n",
       "\n",
       "        whole_mean_sd_1  whole_mean_curr_1  whole_mean_dt_2  whole_mean_sd_2  \\\n",
       "18             2.977180         108.360000         0.007782         2.608600   \n",
       "19             3.961489         118.638298         0.007403         6.045319   \n",
       "20             7.299608         115.549020         0.009377         5.986667   \n",
       "21             2.803571         119.142857         0.010334         5.950893   \n",
       "22             4.949231         108.373077         0.009155         5.005962   \n",
       "...                 ...                ...              ...              ...   \n",
       "121833         3.294164         118.232877         0.007300         4.929726   \n",
       "121834         4.511014         110.969565         0.010305         9.105797   \n",
       "121835         3.918438         113.968750         0.006877         4.759687   \n",
       "121836         3.191228         109.354386         0.007419         6.552982   \n",
       "121837         4.090577         105.807692         0.006907         8.702885   \n",
       "\n",
       "        whole_mean_curr_2  whole_mean_dt_3  ...  cluster_2_sd_sd_1  \\\n",
       "18             106.584000         0.007045  ...           2.295391   \n",
       "19             122.489362         0.006636  ...           1.113159   \n",
       "20             125.666667         0.006474  ...           1.764011   \n",
       "21             123.821429         0.010214  ...           1.846205   \n",
       "22             123.750000         0.011251  ...           1.011763   \n",
       "...                   ...              ...  ...                ...   \n",
       "121833         116.342466         0.006555  ...           1.174303   \n",
       "121834         114.927536         0.005568  ...           1.979405   \n",
       "121835         113.562500         0.006410  ...           1.174073   \n",
       "121836         123.263158         0.006472  ...           0.796188   \n",
       "121837         113.134615         0.008337  ...           1.977663   \n",
       "\n",
       "        cluster_2_sd_curr_1  cluster_2_sd_dt_2  cluster_2_sd_sd_2  \\\n",
       "18                 2.368845           0.003721           0.605664   \n",
       "19                 2.396142           0.002825           1.860764   \n",
       "20                 2.193497           0.004701           1.673851   \n",
       "21                 1.564059           0.003473           3.109129   \n",
       "22                 3.794733           0.003542           1.812695   \n",
       "...                     ...                ...                ...   \n",
       "121833             2.235561           0.004556           1.678792   \n",
       "121834             3.978471           0.004743           1.382768   \n",
       "121835             2.582586           0.004565           1.179861   \n",
       "121836             4.831773           0.002296           2.261881   \n",
       "121837             4.798291           0.003249           2.177636   \n",
       "\n",
       "        cluster_2_sd_curr_2  cluster_2_sd_dt_3  cluster_2_sd_sd_3  \\\n",
       "18                 1.576356           0.003138           0.442328   \n",
       "19                 2.381905           0.004161           1.457417   \n",
       "20                 1.558126           0.003241           0.891852   \n",
       "21                 2.829401           0.005521           1.089678   \n",
       "22                 2.289105           0.008535           0.998551   \n",
       "...                     ...                ...                ...   \n",
       "121833             2.706338           0.005078           2.342449   \n",
       "121834             2.568104           0.003849           0.796583   \n",
       "121835             1.791664           0.003236           1.046608   \n",
       "121836             2.397088           0.001914           0.543752   \n",
       "121837             3.596874           0.004098           1.326168   \n",
       "\n",
       "        cluster_2_sd_curr_3          gene_id  label  \n",
       "18                 2.147127  ENSG00000003056      0  \n",
       "19                 2.129269  ENSG00000003056      0  \n",
       "20                 1.524671  ENSG00000003056      0  \n",
       "21                 1.202462  ENSG00000003056      0  \n",
       "22                 1.012373  ENSG00000003056      0  \n",
       "...                     ...              ...    ...  \n",
       "121833             3.736387  ENSG00000167747      1  \n",
       "121834             3.087344  ENSG00000167747      0  \n",
       "121835             1.858941  ENSG00000167747      1  \n",
       "121836             1.941561  ENSG00000167747      0  \n",
       "121837             3.045585  ENSG00000167747      0  \n",
       "\n",
       "[96821 rows x 140 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV 1/5] END .logistic__C=9.999999999999999e-05;, score=0.046 total time=   0.8s\n",
      "[CV 2/5] END .logistic__C=9.999999999999999e-05;, score=0.046 total time=   0.8s\n",
      "[CV 3/5] END .logistic__C=9.999999999999999e-05;, score=0.046 total time=   0.8s\n",
      "[CV 4/5] END .logistic__C=9.999999999999999e-05;, score=0.046 total time=   0.8s\n",
      "[CV 5/5] END .logistic__C=9.999999999999999e-05;, score=0.046 total time=   0.8s\n",
      "[CV 1/5] END ..logistic__C=0.000774263682681127;, score=0.080 total time=   0.8s\n",
      "[CV 2/5] END ..logistic__C=0.000774263682681127;, score=0.083 total time=   0.9s\n",
      "[CV 3/5] END ..logistic__C=0.000774263682681127;, score=0.084 total time=   0.8s\n",
      "[CV 4/5] END ..logistic__C=0.000774263682681127;, score=0.085 total time=   0.8s\n",
      "[CV 5/5] END ..logistic__C=0.000774263682681127;, score=0.075 total time=   0.8s\n",
      "[CV 1/5] END ..logistic__C=0.005994842503189409;, score=0.205 total time=   2.5s\n",
      "[CV 2/5] END ..logistic__C=0.005994842503189409;, score=0.203 total time=   2.6s\n",
      "[CV 3/5] END ..logistic__C=0.005994842503189409;, score=0.197 total time=   2.7s\n",
      "[CV 4/5] END ..logistic__C=0.005994842503189409;, score=0.198 total time=   2.7s\n",
      "[CV 5/5] END ..logistic__C=0.005994842503189409;, score=0.182 total time=   2.7s\n",
      "[CV 1/5] END ..logistic__C=0.046415888336127774;, score=0.243 total time=  24.6s\n",
      "[CV 2/5] END ..logistic__C=0.046415888336127774;, score=0.251 total time=  37.3s\n",
      "[CV 3/5] END ..logistic__C=0.046415888336127774;, score=0.231 total time=  32.9s\n",
      "[CV 4/5] END ..logistic__C=0.046415888336127774;, score=0.246 total time=  30.9s\n",
      "[CV 5/5] END ..logistic__C=0.046415888336127774;, score=0.220 total time=  30.9s\n",
      "[CV 1/5] END ....logistic__C=0.3593813663804626;, score=0.251 total time= 2.1min\n",
      "[CV 2/5] END ....logistic__C=0.3593813663804626;, score=0.265 total time= 2.4min\n",
      "[CV 3/5] END ....logistic__C=0.3593813663804626;, score=0.237 total time= 1.8min\n",
      "[CV 4/5] END ....logistic__C=0.3593813663804626;, score=0.258 total time= 2.1min\n",
      "[CV 5/5] END ....logistic__C=0.3593813663804626;, score=0.224 total time= 2.5min\n",
      "[CV 1/5] END .....logistic__C=2.782559402207126;, score=0.251 total time= 4.4min\n",
      "[CV 2/5] END .....logistic__C=2.782559402207126;, score=0.267 total time= 4.3min\n",
      "[CV 3/5] END .....logistic__C=2.782559402207126;, score=0.237 total time= 4.1min\n",
      "[CV 4/5] END .....logistic__C=2.782559402207126;, score=0.259 total time= 4.7min\n",
      "[CV 5/5] END .....logistic__C=2.782559402207126;, score=0.224 total time= 4.5min\n",
      "[CV 1/5] END .....logistic__C=21.54434690031882;, score=0.251 total time= 5.3min\n",
      "[CV 2/5] END .....logistic__C=21.54434690031882;, score=0.267 total time= 5.3min\n",
      "[CV 3/5] END .....logistic__C=21.54434690031882;, score=0.237 total time= 4.9min\n",
      "[CV 4/5] END .....logistic__C=21.54434690031882;, score=0.258 total time= 5.4min\n",
      "[CV 5/5] END .....logistic__C=21.54434690031882;, score=0.224 total time= 5.4min\n",
      "[CV 1/5] END ....logistic__C=166.81005372000556;, score=0.251 total time= 4.9min\n",
      "[CV 2/5] END ....logistic__C=166.81005372000556;, score=0.267 total time= 5.0min\n",
      "[CV 3/5] END ....logistic__C=166.81005372000556;, score=0.237 total time= 5.0min\n",
      "[CV 4/5] END ....logistic__C=166.81005372000556;, score=0.258 total time= 5.4min\n",
      "[CV 5/5] END ....logistic__C=166.81005372000556;, score=0.224 total time= 5.0min\n",
      "[CV 1/5] END ....logistic__C=1291.5496650148827;, score=0.251 total time= 5.2min\n",
      "[CV 2/5] END ....logistic__C=1291.5496650148827;, score=0.267 total time= 5.3min\n",
      "[CV 3/5] END ....logistic__C=1291.5496650148827;, score=0.237 total time= 5.0min\n",
      "[CV 4/5] END ....logistic__C=1291.5496650148827;, score=0.258 total time= 5.6min\n",
      "[CV 5/5] END ....logistic__C=1291.5496650148827;, score=0.224 total time= 5.2min\n",
      "[CV 1/5] END ...............logistic__C=10000.0;, score=0.251 total time= 5.3min\n",
      "[CV 2/5] END ...............logistic__C=10000.0;, score=0.267 total time= 4.9min\n",
      "[CV 3/5] END ...............logistic__C=10000.0;, score=0.237 total time= 4.7min\n",
      "[CV 4/5] END ...............logistic__C=10000.0;, score=0.258 total time= 5.2min\n",
      "[CV 5/5] END ...............logistic__C=10000.0;, score=0.224 total time= 5.1min\n",
      "Selected features: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  72\n",
      "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
      "  91  92  93  95  96  97  98 100 101 102 103 104 105 106 108 109 110 111\n",
      " 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129\n",
      " 130 131 133 134]\n",
      "Best regularization strength (C): 2.782559402207126\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Example dataset (replace with your own)\n",
    "# X: Features, y: Binary target\n",
    "X = train_df.drop(columns = [\"transcript_id\", \"transcript_position\", \"seq\", \"gene_id\", \"label\"])\n",
    "y = train_df[\"label\"]\n",
    "\n",
    "# Step 1: Set up Logistic Regression with L1 (Lasso) penalty\n",
    "logistic = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "\n",
    "# Step 2: Set up the cross-validation grid\n",
    "# 'C' is the inverse of regularization strength; smaller values imply stronger regularization\n",
    "param_grid = {\n",
    "    'logistic__C': np.logspace(-4, 4, 10)  # Search over a range of values for 'C'\n",
    "}\n",
    "\n",
    "# Step 3: Use a pipeline for scaling and modeling\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Standardize features (important for regularization)\n",
    "    ('logistic', logistic)\n",
    "])\n",
    "\n",
    "# Step 4: Set up GridSearchCV for cross-validation\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='average_precision', verbose = 3)  # Adjust scoring if needed\n",
    "\n",
    "# Step 5: Fit the model with cross-validation\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Step 6: Get the best model and the selected features\n",
    "best_model = grid_search.best_estimator_\n",
    "logistic_model = best_model.named_steps['logistic']\n",
    "\n",
    "# Step 7: Identify selected features (non-zero coefficients)\n",
    "selected_features = np.where(logistic_model.coef_[0] != 0)[0]\n",
    "\n",
    "print(f\"Selected features: {selected_features}\")\n",
    "print(f\"Best regularization strength (C): {grid_search.best_params_['logistic__C']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_pr_auc = X.columns[selected_features].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/features_pr_auc.json\",\"w\") as file:\n",
    "    json.dump(features_pr_auc, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
